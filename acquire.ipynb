{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7ddc18cf-e80b-4a3a-b572-58324dbc4087",
   "metadata": {},
   "source": [
    "# Time Series Analysis\n",
    "\n",
    "## Data Acquisition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3247552a-ecd5-46cb-8a76-54fe190b20b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "import os\n",
    "import acquire"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e6845c4-9788-4471-a1ef-67f20e8793c6",
   "metadata": {},
   "source": [
    "1) Using the code from the lesson as a guide and the REST API from https://python.zgulde.net/api/v1/items as we did in the lesson, create a dataframe named items that has all of the data for items."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a89311c3-440b-476f-a837-adcac9ef46e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_items(use_cache=True):\n",
    "    \n",
    "    filename = 'items.csv'\n",
    "    if os.path.exists(filename) and use_cache:\n",
    "        return pd.read_csv(filename)\n",
    "    \n",
    "    domain = 'https://api.data.codeup.com'\n",
    "    endpoint = '/api/v1/items'\n",
    "    items = []\n",
    "\n",
    "    while endpoint != None:\n",
    "        url = domain + endpoint\n",
    "        response = requests.get(url)\n",
    "        data = response.json()\n",
    "        items.extend(data['payload']['items'])\n",
    "        endpoint = data['payload']['next_page']\n",
    "\n",
    "    items = pd.DataFrame(items)\n",
    "    items.to_csv('items.csv',index=False)\n",
    "    return items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f255d44f-30d3-4c41-b46e-48ec19514682",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>item_brand</th>\n",
       "      <th>item_id</th>\n",
       "      <th>item_name</th>\n",
       "      <th>item_price</th>\n",
       "      <th>item_upc12</th>\n",
       "      <th>item_upc14</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Riceland</td>\n",
       "      <td>1</td>\n",
       "      <td>Riceland American Jazmine Rice</td>\n",
       "      <td>0.84</td>\n",
       "      <td>35200264013</td>\n",
       "      <td>35200264013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Caress</td>\n",
       "      <td>2</td>\n",
       "      <td>Caress Velvet Bliss Ultra Silkening Beauty Bar...</td>\n",
       "      <td>6.44</td>\n",
       "      <td>11111065925</td>\n",
       "      <td>11111065925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Earths Best</td>\n",
       "      <td>3</td>\n",
       "      <td>Earths Best Organic Fruit Yogurt Smoothie Mixe...</td>\n",
       "      <td>2.43</td>\n",
       "      <td>23923330139</td>\n",
       "      <td>23923330139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Boars Head</td>\n",
       "      <td>4</td>\n",
       "      <td>Boars Head Sliced White American Cheese - 120 Ct</td>\n",
       "      <td>3.14</td>\n",
       "      <td>208528800007</td>\n",
       "      <td>208528800007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Back To Nature</td>\n",
       "      <td>5</td>\n",
       "      <td>Back To Nature Gluten Free White Cheddar Rice ...</td>\n",
       "      <td>2.61</td>\n",
       "      <td>759283100036</td>\n",
       "      <td>759283100036</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       item_brand  item_id                                          item_name  \\\n",
       "0        Riceland        1                     Riceland American Jazmine Rice   \n",
       "1          Caress        2  Caress Velvet Bliss Ultra Silkening Beauty Bar...   \n",
       "2     Earths Best        3  Earths Best Organic Fruit Yogurt Smoothie Mixe...   \n",
       "3      Boars Head        4   Boars Head Sliced White American Cheese - 120 Ct   \n",
       "4  Back To Nature        5  Back To Nature Gluten Free White Cheddar Rice ...   \n",
       "\n",
       "   item_price    item_upc12    item_upc14  \n",
       "0        0.84   35200264013   35200264013  \n",
       "1        6.44   11111065925   11111065925  \n",
       "2        2.43   23923330139   23923330139  \n",
       "3        3.14  208528800007  208528800007  \n",
       "4        2.61  759283100036  759283100036  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "items = acquire.get_items()\n",
    "items.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80629398-16ff-4203-9dec-b13af67570b1",
   "metadata": {},
   "source": [
    "2) Do the same thing, but for stores (https://python.zgulde.net/api/v1/stores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "70d98d3d-ea30-4258-93d6-5871afd7b9ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_stores(use_cache=True):\n",
    "    \n",
    "    filename = 'stores.csv'\n",
    "    if os.path.exists(filename) and use_cache:\n",
    "        return pd.read_csv(filename)\n",
    "    \n",
    "    domain = 'https://api.data.codeup.com'\n",
    "    endpoint = '/api/v1/stores'\n",
    "    stores = []\n",
    "\n",
    "    while endpoint != None:\n",
    "        url = domain + endpoint\n",
    "        response = requests.get(url)\n",
    "        data = response.json()\n",
    "        stores.extend(data['payload']['stores'])\n",
    "        endpoint = data['payload']['next_page']\n",
    "\n",
    "    stores = pd.DataFrame(stores)\n",
    "    stores.to_csv('stores.csv',index=False)\n",
    "    return stores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fe76a38e-76fd-4388-831d-22c56e7da23f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>store_address</th>\n",
       "      <th>store_city</th>\n",
       "      <th>store_id</th>\n",
       "      <th>store_state</th>\n",
       "      <th>store_zipcode</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12125 Alamo Ranch Pkwy</td>\n",
       "      <td>San Antonio</td>\n",
       "      <td>1</td>\n",
       "      <td>TX</td>\n",
       "      <td>78253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9255 FM 471 West</td>\n",
       "      <td>San Antonio</td>\n",
       "      <td>2</td>\n",
       "      <td>TX</td>\n",
       "      <td>78251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2118 Fredericksburg Rdj</td>\n",
       "      <td>San Antonio</td>\n",
       "      <td>3</td>\n",
       "      <td>TX</td>\n",
       "      <td>78201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>516 S Flores St</td>\n",
       "      <td>San Antonio</td>\n",
       "      <td>4</td>\n",
       "      <td>TX</td>\n",
       "      <td>78204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1520 Austin Hwy</td>\n",
       "      <td>San Antonio</td>\n",
       "      <td>5</td>\n",
       "      <td>TX</td>\n",
       "      <td>78218</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             store_address   store_city  store_id store_state  store_zipcode\n",
       "0   12125 Alamo Ranch Pkwy  San Antonio         1          TX          78253\n",
       "1         9255 FM 471 West  San Antonio         2          TX          78251\n",
       "2  2118 Fredericksburg Rdj  San Antonio         3          TX          78201\n",
       "3          516 S Flores St  San Antonio         4          TX          78204\n",
       "4          1520 Austin Hwy  San Antonio         5          TX          78218"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stores = acquire.get_stores()\n",
    "stores.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5942cb3c-2e0e-4d05-9623-eb3adc7fac86",
   "metadata": {},
   "source": [
    "3) Extract the data for sales (https://python.zgulde.net/api/v1/sales). There are a lot of pages of data here, so your code will need to be a little more complex. Your code should continue fetching data from the next page until all of the data is extracted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b7a8c4d8-33c7-456d-a7c1-8892389db946",
   "metadata": {},
   "outputs": [],
   "source": [
    "# url = 'https://api.data.codeup.com/api/v1/sales'\n",
    "# requests.get(url).json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2db25bef-042c-40bf-b474-c9a69a0d57e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sales(use_cache=True):\n",
    "    \n",
    "    filename = 'sales.csv'\n",
    "    if os.path.exists(filename) and use_cache:\n",
    "        return pd.read_csv(filename)\n",
    "    \n",
    "    domain = 'https://api.data.codeup.com'\n",
    "    endpoint = '/api/v1/sales'\n",
    "    sales = []\n",
    "\n",
    "    while endpoint != None:\n",
    "        url = domain + endpoint\n",
    "        response = requests.get(url)\n",
    "        data = response.json()\n",
    "        sales.extend(data['payload']['sales'])\n",
    "        endpoint = data['payload']['next_page']\n",
    "        print(f'\\r{endpoint}', end =' ')\n",
    "\n",
    "    sales = pd.DataFrame(sales)\n",
    "    sales.to_csv('sales.csv',index=False)\n",
    "    return sales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "92050144-e174-420d-b1a8-84bcb2bbb8ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>item</th>\n",
       "      <th>sale_amount</th>\n",
       "      <th>sale_date</th>\n",
       "      <th>sale_id</th>\n",
       "      <th>store</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>13.0</td>\n",
       "      <td>Tue, 01 Jan 2013 00:00:00 GMT</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>11.0</td>\n",
       "      <td>Wed, 02 Jan 2013 00:00:00 GMT</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>14.0</td>\n",
       "      <td>Thu, 03 Jan 2013 00:00:00 GMT</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>13.0</td>\n",
       "      <td>Fri, 04 Jan 2013 00:00:00 GMT</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>10.0</td>\n",
       "      <td>Sat, 05 Jan 2013 00:00:00 GMT</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   item  sale_amount                      sale_date  sale_id  store\n",
       "0     1         13.0  Tue, 01 Jan 2013 00:00:00 GMT        1      1\n",
       "1     1         11.0  Wed, 02 Jan 2013 00:00:00 GMT        2      1\n",
       "2     1         14.0  Thu, 03 Jan 2013 00:00:00 GMT        3      1\n",
       "3     1         13.0  Fri, 04 Jan 2013 00:00:00 GMT        4      1\n",
       "4     1         10.0  Sat, 05 Jan 2013 00:00:00 GMT        5      1"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sales = acquire.get_sales()\n",
    "sales.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f290fecb-6fe1-4b15-b977-dfe9014ef6d6",
   "metadata": {},
   "source": [
    "4) Save the data in your files to local csv files so that it will be faster to access in the future."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "22a7bdee-a2d1-4140-9869-1ad4cb51eef0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sales.to_csv('sales.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c39b230c-3dde-4e5d-880b-114d8f020e7e",
   "metadata": {},
   "source": [
    "5) Combine the data from your three separate dataframes into one large dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c472e6da-cd52-476f-8a47-b3a89204845f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# combined = sales.merge(items,left_on='item',right_on='item_id').merge(stores,left_on='store',right_on='store_id')\n",
    "# combined.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9b941ac6-a871-459c-b2fa-06a1f6aee7b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine(sales, items, stores):\n",
    "    \n",
    "    combined = sales.merge(items,left_on='item',right_on='item_id')\n",
    "    combined = combined.merge(stores,left_on='store',right_on='store_id')\n",
    "    \n",
    "    return combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "393fd1a7-35c1-497d-983f-0ff6291ad424",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'store_id'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/lg/ftvnw2s97_z5h66qcl3vwwf00000gn/T/ipykernel_8093/290010032.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mcombine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0macquire\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcombine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mcombine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/codeup-data-science/time-series-exercises/acquire.py\u001b[0m in \u001b[0;36mcombine\u001b[0;34m()\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m     \u001b[0mcombined\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msales\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmerge\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mleft_on\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'item'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mright_on\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'item_id'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 76\u001b[0;31m     \u001b[0mcombined\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcombined\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmerge\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstores\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mleft_on\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'store'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mright_on\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'store_id'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     77\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mcombined\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/homebrew/anaconda3/lib/python3.9/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36mmerge\u001b[0;34m(self, right, how, on, left_on, right_on, left_index, right_index, sort, suffixes, copy, indicator, validate)\u001b[0m\n\u001b[1;32m   9188\u001b[0m         \u001b[0;32mfrom\u001b[0m \u001b[0mpandas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmerge\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmerge\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   9189\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 9190\u001b[0;31m         return merge(\n\u001b[0m\u001b[1;32m   9191\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   9192\u001b[0m             \u001b[0mright\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/homebrew/anaconda3/lib/python3.9/site-packages/pandas/core/reshape/merge.py\u001b[0m in \u001b[0;36mmerge\u001b[0;34m(left, right, how, on, left_on, right_on, left_index, right_index, sort, suffixes, copy, indicator, validate)\u001b[0m\n\u001b[1;32m    104\u001b[0m     \u001b[0mvalidate\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m ) -> DataFrame:\n\u001b[0;32m--> 106\u001b[0;31m     op = _MergeOperation(\n\u001b[0m\u001b[1;32m    107\u001b[0m         \u001b[0mleft\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m         \u001b[0mright\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/homebrew/anaconda3/lib/python3.9/site-packages/pandas/core/reshape/merge.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, left, right, how, on, left_on, right_on, axis, left_index, right_index, sort, suffixes, copy, indicator, validate)\u001b[0m\n\u001b[1;32m    697\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mright_join_keys\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    698\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin_names\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 699\u001b[0;31m         ) = self._get_merge_keys()\n\u001b[0m\u001b[1;32m    700\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    701\u001b[0m         \u001b[0;31m# validate the merge keys dtypes. We may need to coerce\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/homebrew/anaconda3/lib/python3.9/site-packages/pandas/core/reshape/merge.py\u001b[0m in \u001b[0;36m_get_merge_keys\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1094\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_rkey\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1095\u001b[0m                         \u001b[0;32mif\u001b[0m \u001b[0mrk\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1096\u001b[0;31m                             \u001b[0mright_keys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mright\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_label_or_level_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1097\u001b[0m                         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1098\u001b[0m                             \u001b[0;31m# work-around for merge_asof(right_index=True)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/homebrew/anaconda3/lib/python3.9/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m_get_label_or_level_values\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1777\u001b[0m             \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maxes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_level_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1778\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1779\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1780\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1781\u001b[0m         \u001b[0;31m# Check for duplicates\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'store_id'"
     ]
    }
   ],
   "source": [
    "combine = acquire.combine()\n",
    "combine.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e0a683e-cb01-4b59-9d58-cd4420398092",
   "metadata": {},
   "source": [
    "6) Acquire the Open Power Systems Data for Germany, which has been rapidly expanding its renewable energy production in recent years. The data set includes country-wide totals of electricity consumption, wind power production, and solar power production for 2006-2017. You can get the data here: https://raw.githubusercontent.com/jenfly/opsd/master/opsd_germany_daily.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3a3bb7e-a335-40d2-b80d-6d65226eca5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "power = pd.read_csv('https://raw.githubusercontent.com/jenfly/opsd/master/opsd_germany_daily.csv')\n",
    "power.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9543d50e-c480-4640-b805-30023ac84f87",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_power_data(use_cache=True):\n",
    "    '''\n",
    "    A function to acquire the German power systems data\n",
    "    '''\n",
    "    # Assign filename to look up\n",
    "    filename = 'german_power.csv'\n",
    "    \n",
    "    #Check for file and return csv if present\n",
    "    if os.path.exists(filename) and use_cache:\n",
    "        return pd.read_csv(filename)\n",
    "    \n",
    "    # Aquire data\n",
    "    power = pd.read_csv('https://raw.githubusercontent.com/jenfly/opsd/master/opsd_germany_daily.csv')\n",
    "    \n",
    "    # Assign to CSV\n",
    "    power.to_csv('german_power.csv',index=False)\n",
    "    \n",
    "    # Return power\n",
    "    return power\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90f9717c-822d-4c89-bdc5-de69045af2c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "power = acquire.get_power_data()\n",
    "power.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "987d9188-5e6e-4977-a612-94e183f094e2",
   "metadata": {},
   "source": [
    "7) Make sure all the work that you have done above is reproducible. That is, you should put the code above into separate functions in the acquire.py file and be able to re-run the functions and get the same data."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
